## Project report

---

**Advanced Lane Finding Project**

The goals / steps of this project are the following:

* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.
* Apply a distortion correction to raw images.
* Use color transforms, gradients, etc., to create a thresholded binary image.
* Apply a perspective transform to rectify binary image ("birds-eye view").
* Detect lane pixels and fit to find the lane boundary.
* Determine the curvature of the lane and vehicle position with respect to center.
* Warp the detected lane boundaries back onto the original image.
* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.

[//]: # (Image References)

[image1]: ./examples/undistorted.png "Undistorted"
[image2]: ./example/sample_undistort.png "Calibration"
[image3]: ./example/masked_image.png "Mask"
[image4]: ./examples/after_thresholding.png "color transforms and gradients"
[image5]: ./examples/perspective.png "Birds-eye view"
[image5]: ./examples/lane_finding_poly_fit.jpg "Fit Visual"
[image7]: ./examples/final_image.png "Final image"
[video1]: ./project_video.mp4 "Video"

## [Rubric](https://review.udacity.com/#!/rubrics/571/view) Points

---

## README

The code for implementing entire project is contained in a IPython notebook located in "./examples/example.ipynb". Details are provided below. 

### Camera Calibration

#### 1. Perform camera calibration. 

Steps followed are as follows.
* we use chessboard images to calibrate our camera. Multiple images are used to obtain information required to overcome camera distortion. 
* Assuming the real world coordinates of chessboard coners are known (*imgpoints*), and detect the same from images (*objpoints*) using openCV function, findChessboardCorners. Using this information, we compute distortion coefficients and camera matrix with the help of calibrateCamera function in openCV. 
* Original and undistorted images are shown below. Observe that, the curved lines in original image are due to distortion and are corrected in image on right.

![alt text][image1]

### Pipeline (single images)

#### 1.Sample distortion corrected image

* we pick a sample test image and undistort it using camera matrix and distortion coefficients computed in camera calibration section.

* undistorted image is denoted as **image_undistort** in our code.

![alt text][image2]

#### 2. Masking of undistorted image

* Next, I defined a portion of the image that could most likely contain all the lane information needed and process only this part of the image, thereby avoiding all the background inforamtion. 

```python
vertices = np.array([[(100,680),
                      (575, 400), 
                      (700, 400), 
                      (1270,680)]], dtype=np.int32)

```
* This masked output is saved as **image** in our code. Further processing of lane detection is performed on this masked image.

![alt text][image3]
#### 3.Applying colour and gradient threasholds to obtain lane images

* we define few functions to compute gradients and colour thresholds in our code. In the image below we show a set of images obtained by applying gradient and colour thresholds on our image.

* Following different properties of image have be used to obtain lane information.
    * Gradient in x-direction
    * Magnitude of gradient
    * S-channel 
    * H-channel
    
* **One of the major problem is the additional unncessary gradient information generated by region masking. I removed these points in the final image by masking the processed imaged with a finer region comprising of a polygon that is a subset of original mask but doesnot result in lane information loss.**

``` python
vertices = np.array([[(120,700),
                      (575, 405), 
                      (700, 405), 
                      (1220,700)]], dtype=np.int32)

```
![alt text][image4]

#### 3. Applying perspective transformation to compute radius of curvature

* Next we applied perspective transforamtion to obtain bird's eye view of the lane. I performed a careful search for source and destination point to get a good warped image for straight lanes and used it for all images.

```python
src = np.float32(
        [[535,490],
         [760,490],
         [200,720],
         [1150,720]])
dst = np.float32(
        [[150,0],
         [1100,0],
         [150,700],
         [1100,700]])
```

This resulted in the following source and destination points:

| Source        | Destination   | 
|:-------------:|:-------------:| 
| 535, 490      | 150, 0        | 
| 760, 490      | 1100,  0      |
| 200, 720      | 150, 700      |
| 1150, 720     | 1100, 700     |

* Observerd that both lanes are parallel as shown below.

![alt text][image5]

#### 4. Detecting lane pixels and fitting a polynomial for lane markings

* Next, using the bird's eye view of the processed lane image, a polynomial is fitted for the lane lines. 

* Sliding window approach, recoginising clusters of lane pixels is followed to group pixels corresponding to left and right lanes as shown in below figure.

* Numpy function *polyfit* is used to fit a second order polynomial for both lanes. 

![alt text][image6]

#### 5.Computing Radius of curvatue and deviation from center of lane in real world

* Using the polynomial fit computed in above secition, radius of curvature of both lanes is computed for real world usage.

* Further, assuming that the camera is mounted on the center of the lane in a striaght lane, I computed the position with respect to center of lane by substracting the mid point of left fit  and right fit lanes and the center of image.

#### 6. Example image of your result plotted back down onto the road such that the lane area is identified clearly.

![alt text][image7]

---

### Pipeline (video)

#### 1. Final video output.  

Here's a [link to my video result](./examples/result.mp4)

---

### Discussion

#### 1. Briefly discuss any problems / issues  faced in your implementation of this project.  Where will your pipeline likely fail?  What could you do to make it more robust?

* I am having some problem with radius of curvature computation. Both lanes have different values. For straight lanes, even though the radius of curvature is high but slightly difference in left and right lane is huge. In the video I have also missed few frames which have shadows and changes in texture of lane. May be using the prior frame inforamtion will help.  
